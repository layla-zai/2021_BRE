---
title: ''
output: html_document
---

```{r setup, include=FALSE}
# load libraries
library(tidyverse)
library(conflicted)

# additional libraries for today
library(viridis)
library(magrittr)
library(broom)
library(pheatmap)

# resolve package conflicts
filter <- dplyr::filter
select <- dplyr::select
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 2021-07-14: Clustering

Please email me your Rmarkdown document at <kkeith@coriell.org> with your **LAST NAME** in the file name by 9AM Friday 7/15

---

We'll practice clustering with 3 different datasets

### wine

The wine dataset contains the results of a chemical analysis of wines grown in a specific area of Italy. Three types of wine are represented in the 178 samples, with the results of 13 chemical analyses recorded for each sample. The Type variable has been transformed into a categoric variable. The tidy wine dataset contains the following columns:

- **Sample** = the unique sample ID for each row
- **Cultivar** = the number factor indicating the grape cultivar the wine was made from
- **Alcohol** = the alcohol concentration in the wine sample (g/L)
- **MalicAcid** = the malic acid concentration in the wine sample (g/L)
- **Ash** = the ash concentration in the wine sample (g/L)
- **Magnesium** = the magnesium concentration in the wine sample (g/L)
- **TotalPhenol** = the total amount of all phenol compounds in the wine sample (g/L)
- **Flavanoids** = the concentration of all flavanoids in the wine sample (g/L)
- **NonflavPhenols** = the concentration of all non-flavanoid phenols in the wine sample (g/L)
- **Color** = wine color (spectrophotometric measure?)

In the wine dataset, Cultivar is a **categorical** variable (even though it's coded using numbers) that we'll try to discriminate using clustering.

---

Read in the wine dataset in the chunk below.

```{r}
read_tsv('data/data/wine.tsv') -> wine
```

#### heatmp

1. Plot a heatmap of the `wine` dataset. Annotate it with the cultivar of the sample.

```{r}
wine %>% 
  select(-Cultivar) %>% 
  as.data.frame() %>% 
  column_to_rownames('Sample') -> wine_nocult

data.frame(Cultivar = wine$Cultivar,
           row.names = rownames(wine_nocult)) -> wine_row_ann

list(Cultivar = c('1' = 'yellow', 
                  '2' = 'red',
                  '3' = 'firebrick4')) -> wine_ann_colors

pheatmap(wine_nocult,
         show_rownames = F,
         color = viridis(50),
         cutree_cols = 2,
         scale = 'row',
         annotation_row = wine_row_ann,
         annotation_colors = wine_ann_colors)
```

2. Does the heatmap do a good job of discriminating the cultivar? Why or why not?

**WRITE YOUR ANSWER HERE** The heatjob doesn't do the best job because Cultivar 1 seems too distinct from the others so most of the data shows in the Magnesium column.

#### PCA

3. Plot a PCA of the wine dataset. Start by plotting PC1 and PC2.

```{r}
wine %>% select(-Sample, -Cultivar) %>% prcomp() %>% augment(wine) -> wine_pca

ggplot(wine_pca, aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(aes(color = as.factor(Cultivar))) +
  labs(x = 'PC1', y = 'PC2', color = 'Cultivar') +
  theme_classic(base_size = 20)
```

4. Does the PCA do a good job of discriminating the cultivar? Why or why not?

**WRITE YOUR ANSWER HERE** The PCA does an okay job but there is still a lot of overlap so the discrimination isn't very good. 

5. Does any combination of the first 3 PCs do a good job of discriminating the cultivar? Can any cultivar be distinguished from the others? Why or why not? Plot the PCs in the chunk below and explain your reasoning.

**WRITE YOUR ANSWER HERE** PC1 and PC2 do help separate the cultivars a bit, and PC1 and PC3 work just as well. However, using PC2 and PC3 makes it a lot easier to distinguish Cultivar 3 from the other two. 

```{r}
# PC! vs PC2
ggplot(wine_pca, aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(aes(color = as.factor(Cultivar))) +
  labs(x = 'PC1', y = 'PC2', color = 'Cultivar') +
  theme_classic(base_size = 20)

# PC1 vs PC3
ggplot(wine_pca, aes(x = .fittedPC1, y = .fittedPC3)) +
  geom_point(aes(color = as.factor(Cultivar))) +
  labs(x = 'PC1', y = 'PC3', color = 'Cultivar') +
  theme_classic(base_size = 20)

# PC2 vs PC3
ggplot(wine_pca, aes(x = .fittedPC2, y = .fittedPC3)) +
  geom_point(aes(color = as.factor(Cultivar))) +
  labs(x = 'PC2', y = 'PC3', color = 'Cultivar') +
  theme_classic(base_size = 20)
```

#### kmeans

6. Run kmeans clustering with 3 clusters on the wine dataset and plot the results

```{r}
wine %>% 
  select(-Sample, -Cultivar) %>% 
  kmeans(3) %>% 
  augment(wine) -> wine_k3

ggplot(wine_k3, aes(x = Magnesium, y = Alcohol)) +
  geom_point(aes(color = .cluster, shape = as.factor(Cultivar))) +
  theme_classic()

ggplot(wine_k3, aes(x = Magnesium, y = Alcohol)) +
  geom_point(aes(color = .cluster)) +
  facet_wrap(~ Cultivar) +
  theme_classic()
```

7. Does kmeans do a good job of discriminating the cultivars? Why or why not?

**WRITE YOUR ANSWER HERE** Not really, as the three cultivars have a lot of overlap. 

<br>

### biopsy

In the biopsy dataset, outcome is the categorical variable that we'll try to recover. All the information about the dataset is below for reference.

The biopsy dataset contains the results of breast tumor biopsy results from 699 patients from the University of Wisconsin, Madison. Tumor biopsy attributes were measured on a scale of 1-10 and the diagnosis is given in the outcome column. The tidy biopsy dataset contains the following columns:

- **sample_id** = numeric sample ID
- **outcome** = is the biopsy cancerous or not? character, either 'benign' or 'malignant'
- **clump_thickness** = biopsy thickness on a scale from 1-10
- **uniform_cell_size** = uniformity of cell size on a scale from 1-10
- **marg_adhesion** = marginal adhesion on a scale from 1-10
- **epithelial_cell_size** = epithelial cell size on a scale from 1-10
- **bare_nuclei** = proportion of cells that are mainly nucleus on a scale from 1-10
- **bland_chromatin** = texture of chromatin on a scale from 1-10
- **normal_nucleoli** = proportion of cells with normal nucleoli on a scale from 1-10
- **mitoses** = proportion of mitoses on a scale from 1-10

---

Use the chunk below to read in the biopsy table

```{r}
read_csv('data/data/biopsy.csv') -> biopsy
```

#### PCA

8. Run a PCA on the biopsy dataset and plot the first two PCs. How does the PCA analysis discriminate the outcomes?

**WRITE YOUR ANSWER HERE** The PCA analysis does a good job because the benign biopsies are clustered mostly to the right and separated from the malignant biopsies. 

```{r}
biopsy %>% select(-sample_id, -outcome) %>% prcomp() %>% augment(biopsy) -> biopsy_pca

ggplot(biopsy_pca, aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(aes(color = outcome)) +
  theme_classic()
```

#### kmeans

9. Run kmeans clustering with two clusters on the biopsy dataset. How does kmeans clustering do to discriminate the data?

**WRITE YOUR ANSWER HERE** It does a good job because there is little overlap between the different clusters. 

```{r}
biopsy %>% 
  select(-sample_id, -outcome) %>% 
  kmeans(2) %>% 
  augment(biopsy) -> biopsy_k3

# plot with color and facets
ggplot(biopsy_k3, aes(x = clump_thickness)) +
  geom_histogram(aes(fill = .cluster), alpha = 0.5, position = 'identity') +
  facet_wrap(~ outcome) +
  theme_classic()
```

#### heatmap

10. Plot a heatmp using the biopsy dataset. Annotate the heatmap with the outcome. How does it do discriminating the outcomes?

**WRITE YOUR ANSWER HERE** It does a good job because there's a strong difference between groups with the cancer data.

```{r}
biopsy %>% 
  select(-outcome) %>% 
  column_to_rownames('sample_id') -> biopsy_noout

data.frame(outcome = biopsy$outcome,
           row.names = rownames(biopsy_noout)) -> biopsy_row_ann

list(outcome = c('benign' = 'skyblue', 
                 'malignant' = 'firebrick')) -> biopsy_ann_colors


pheatmap(biopsy_noout,
         show_rownames = F,
         color = viridis(50),
         cutree_rows = 5,
         annotation_row = biopsy_row_ann,
         annotation_colors = biopsy_ann_colors)

```

---

11. In your opinion, which of the three methods discriminated the outcome the best?

PCA because it has the clearest visual representation.

<br>

### nycflights13

For this last section, we'll use the `flights` table from the `nycflights13` package. There's no variable of interest here; instead we'll do an unbiased clustering analysis in a (relatively) large dataset to see if we can find anything interesting.

```{r}
install.packages('nycflights13')
library(nycflights13)
```

Look at the table. If you need to know what the columns are, look at the documentation (Remember `?flights`)

```{r}
flights
```

#### kmeans

12. Pick the best number of clusters to use for kmeans clustering and explain why you picked that number below.

**How many clusters will you use?**: 7
**EXPLAIN HERE WHY YOU PICKED THAT NUMBER**: I chose 7 because it seems to be the inflection point that occurs before the graph actually levels out too much. 

```{r}
flights %>% 
# drop the categorical columns
  select(-carrier, -tailnum, -origin, -dest, -time_hour) %>% 

  na.omit() -> flights_num

tibble(k = 2:15) %>% 
  mutate(kclust = map(k, ~ kmeans(flights_num, .)),
         kclust = map(kclust, ~ glance(.))) %>%
  unnest(kclust) -> kmeans_params  


kmeans_params %>%
  mutate(group = 1) %>%   
  ggplot(aes(x = as.factor(k), y = tot.withinss, group = group)) + 
    geom_point(size = 3) + 
    geom_line(size = 1) + 
    labs(x = 'Number of Clusters', y = 'Goodness of Fit\n (within cluster sum of squares)') +
    theme_classic() +
    theme(axis.title = element_text(size = 14))
```

13. Run kmeans clustering with your chosen number of clusters, then visualize the kmeans with some plot.

```{r}
flights_num %>%
  kmeans(7) %>% 
  augment(na.omit(flights)) -> flights_k7

ggplot(flights_k7, aes(x = dep_time)) + 
  geom_density(aes(fill = .cluster)) +
  scale_fill_viridis_d() +
  facet_wrap(~ .cluster) +
  labs(x = 'Departure Time (HH:MM)') +
  theme_classic() +
  theme(legend.position = 'none')
```

#### PCA

14. Calculate a PCA and plot PCs one and two fpr the flights dataset.

```{r}
flights_num %>% 
  prcomp(center = T, scale = F) %>% 
  augment(na.omit(flights)) -> flights_pca

ggplot(flights_pca, aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point() +
  labs(x = 'PC1', y = 'PC2') +
  theme_classic()
```

15. Now color the PCA plot by all the categorical variables with the flights dataset. Do any of them go with the patterns of variation identified by the PCA?

**WRITE YOUR ANSWER HERE** "EV" is mainly separated along PC1 but the origin and destination don't show that much of a difference. 

```{r}
ggplot(flights_pca, aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(aes(color = carrier)) +
  labs(x = 'PC1', y = 'PC2') +
  theme_classic()

ggplot(flights_pca, aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(aes(color = origin)) +
  labs(x = 'PC1', y = 'PC2') +
  theme_classic()

ggplot(flights_pca, aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(aes(color = dest)) +
  labs(x = 'PC1', y = 'PC2') +
  theme_classic()
```




